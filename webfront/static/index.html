<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-6B0G64G1JM"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-6B0G64G1JM');
    </script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Object Detection Zero-Shot API Documentation</title>
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Syntax highlighting -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism.min.css" rel="stylesheet">
  <style>
    .endpoint {
      margin-bottom: 2rem;
      padding: 1rem;
      border: 1px solid #dee2e6;
      border-radius: 0.25rem;
    }
    pre {
      background-color: #f8f9fa;
      padding: 1rem;
      border-radius: 0.25rem;
    }
  </style>
    <script type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "SoftwareApplication",
            "name": "Object Detection Zero-Shot",
            "applicationCategory": "BusinessApplication",
            "description": "A demo of zero-shot image classification and detection service using OpenAI's ViT-CLIP model through Hugging Face's inference engine, with Pinecone vector database integration for efficient similarity search.",
            "operatingSystem": "Any",
            "offers": {
                "@type": "Offer",
                "price": "0",
                "priceCurrency": "USD"
            },
            "softwareVersion": "1.0",
            "applicationSuite": "Image Classification",
            "featureList": [
                "Zero-shot image classification",
                "Pinecone Vector database integration",
                "REST API endpoints",
                "Rate limiting",
                "Docker containerization"
            ],
            "requirements": "Docker environment for deployment",
            "softwareHelp": {
                "@type": "CreativeWork",
                "url": "https://github.com/paul-at-nangalan/object-detection-zero-shot/blob/main/README.md"
            },
            "provider": {
                "@type": "Organization",
                "name": "NES Asia"
            }
        }
    </script>
</head>
<body>
<div class="container py-5">
  <h1>Object Detection Zero-Shot</h1>
  <p class="lead">A <strong>demo</strong> of zero-shot image classification and detection service using OpenAI's ViT-CLIP model through Hugging Face's inference engine, with Pinecone vector database integration for efficient similarity search.</p>
    <p>The advantages of zero shot image classification are that the model doesn't need retraining to deal with new images.</p>
  <p><strong>Note: This is for demonstration purposes only. The code can be found <a href="https://github.com/paul-at-nangalan/object-detection-zero-shot">here</a> </strong></p>
    <p></p>
  <h2 class="mt-5">API Endpoints</h2>
  <div class="endpoint">
    <h3>1. Image Embedding (/image/embed)</h3>
    <p>Creates vector embeddings for images and their associated text labels, storing them in Pinecone.</p>

    <h4>Request Format:</h4>
    <pre><code class="language-http">POST /image/embed
Content-Type: multipart/form-data
image: &lt;image_file&gt;
text: &lt;text_description&gt;</code></pre>
    <h4>Response:</h4>
    <pre><code class="language-json">{
    "status": "success",
    "id": "&lt;generated_id&gt;"
}</code></pre>
    <h4>Features:</h4>
    <ul>
      <li>Generates both image and text embeddings using the CLIP model</li>
      <li>Stores embeddings in Pinecone with unique IDs</li>
      <li>Maintains separate vectors for image and text with prefixes "img-" and "text-"</li>
      <li>Rate limited to 30 requests per 24 hours per IP</li>
    </ul>
  </div>
  <div class="endpoint">
    <h3>2. Image Detection (/image/detect)</h3>
    <p>Performs zero-shot object detection on images by comparing them against stored embeddings.</p>

    <h4>Request Format:</h4>
    <pre><code class="language-http">POST /image/detect
Content-Type: multipart/form-data
image: &lt;image_file&gt;</code></pre>
    <h4>Response:</h4>
    <pre><code class="language-json">{
    "score": &lt;similarity_score&gt;,
    "id": "&lt;vector_id&gt;",
    "label": "&lt;matched_label&gt;"
}</code></pre>
    <h4>Features:</h4>
    <ul>
      <li>Generates embeddings for the input image</li>
      <li>Searches Pinecone for similar vectors</li>
      <li>Returns the best match</li>
      <li>Rate limited to 30 requests per 24 hours per IP</li>
    </ul>
  </div>
    <p></p>
  <section class="section">
    <div class="container">
      <h2 class="title is-4">Curl Examples</h2>

      <h3 class="subtitle">1. Image Embed Endpoint</h3>
      <pre><code>curl -X POST https://nesasia.io/image/embed \
-H "Content-Type: multipart/form-data" \
-F "image=@/path/to/your/image.jpg" \
-F "text=description of the image"</code></pre>
      <p>Example Response:</p>
      <pre><code>{
    "status": "success",
    "id": "generated-id"
}</code></pre>
      <h3 class="subtitle">2. Image Detection Endpoint</h3>
      <pre><code>curl -X POST https://nesasia.io/image/detect \
-H "Content-Type: multipart/form-data" \
-F "image=@/path/to/your/image.jpg"</code></pre>
      <p>Example Response:</p>
      <pre><code>{
    "found": true,
    "score": 0.85,
    "label": "matched label"
}</code></pre>
    </div>
  </section>
  <section class="section">
    <div class="container">
        <p></p>
      <h2 class="title is-4">Further Reading</h2>
      <p>For more information about zero-shot image classification using CLIP: <a href="https://www.pinecone.io/learn/series/image-search/zero-shot-image-classification-clip/" target="_blank">Zero-Shot Image Classification with CLIP</a></p>
        <p>See <a href="https://github.com/paul-at-nangalan/object-detection-zero-shot/blob/main/handler.py" target="_blank">handler.py</a> for the huggingface custom handler.</p>
        <p>For details on creating a custom handler for the inference endpoint:
        <a href="https://huggingface.co/docs/inference-endpoints/en/guides/custom_handler" target="_blank">HuggingFace create custom handler</a>.</p>

    </div>
  </section>
    <section class="section">
        <div class="container">
            <p></p>
            <h2 class="title is-4">Questions</h2>
            <p>Please direct any questions to info@nesasia.io</p>

        </div>
    </section>
</div>
<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<!-- Syntax highlighting -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-json.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-http.min.js"></script>
</body>
</html>